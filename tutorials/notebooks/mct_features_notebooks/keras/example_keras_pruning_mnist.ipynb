{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Structured Pruning of a Fully-Connected Keras Model\n",
        "\n",
        "[Run this tutorial in Google Colab](https://colab.research.google.com/github/sony/model_optimization/blob/main/tutorials/notebooks/mct_features_notebooks/keras/example_keras_pruning_mnist.ipynb)\n",
        "\n",
        "Welcome to this tutorial, where we will guide you through training, pruning, and retraining a fully connected Keras model. We'll begin by constructing and training a simple neural network using the Keras framework. Following this, we will introduce and apply model pruning using MCT to reduce the size of our network. Finally, we'll retrain our pruned model to recover its degraded performance due to the pruning process.\n",
        "\n",
        "\n",
        "## Installing TensorFlow and Model Compression Toolkit\n",
        "\n",
        "We start by setting up our environment by installing TensorFlow and Model Compression Toolkit and importing them."
      ],
      "metadata": {
        "id": "UJDzewEYfSN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TF_VER = '2.14.0'\n",
        "\n",
        "!pip install -q tensorflow=={TF_VER}\n",
        "!pip install mct-nightly\n"
      ],
      "metadata": {
        "id": "xTvVA__4NItc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2bAksKtM0ca"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import model_compression_toolkit as mct\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and Preprocessing MNIST\n",
        "\n",
        "Let's create the train and test parts of MNIST dataset including preprocessing:"
      ],
      "metadata": {
        "id": "tW1xcK_Kf4F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the images to [0, 1] range\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0\n"
      ],
      "metadata": {
        "id": "fwtJHnflfv_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Fully-Connected Model\n",
        "\n",
        "In this tutorial section, we create a simple toy example of a fully connected model to demonstrate the pruning process using MCT. It consists of three dense layers with 128, 64, and 10 neurons.\n",
        "\n",
        "Notably, MCT's structured pruning will target the first two dense layers for pruning, as these layers offer the opportunity to reduce output channels. This reduction can be effectively propagated by adjusting the input channels of subsequent layers.\n",
        "\n",
        "Once our model is created, we compile it to prepare the model for training and evaluation.\n"
      ],
      "metadata": {
        "id": "m3vu7-uvgtfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "If3oj5jSjXen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Dense Model on MNIST\n",
        "\n",
        "Now, we can train our model using the dataset we load and evaluate it."
      ],
      "metadata": {
        "id": "Q_tK6Xknbtha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate the model\n",
        "model = create_model()\n",
        "model.fit(train_images, train_labels, epochs=6, validation_data=(test_images, test_labels))\n",
        "\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "jQ3_9Z1WllVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dense Model Properties\n",
        "\n",
        "The model.summary() function in Keras provides a snapshot of the model's architecture, including layers, their types, output shapes, and the number of parameters.\n"
      ],
      "metadata": {
        "id": "ZQHxLrsvcLKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "oxdespw2eeBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's break down what we see in our model summary:\n",
        "\n",
        "- First Dense Layer: A fully connected layer with 128 output channels and 784 input channels.\n",
        "\n",
        "- Second Dense Layer: A fully connected layer with 64 output channels and 128 input channels.\n",
        "\n",
        "- Third Dense Layer: The final dense layer with 10 neurons (as per the number of MNIST classes) and 64 input channels.\n",
        "\n",
        "The total parameters amount to 109,386, which roughly requiers 427.29 KB."
      ],
      "metadata": {
        "id": "GymibwxQehOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MCT Structured Pruning\n",
        "\n",
        "### Create TPC\n",
        "\n",
        "Firstly, we'll set up the Target Platform Capabilities (TPC) to specify each layer's SIMD (Single Instruction, Multiple Data) size.\n",
        "\n",
        "In MCT, SIMD plays a crucial role in channel grouping, affecting the pruning decision process based on channel importance for each SIMD group of channels.\n",
        "\n",
        "We'll use the simplest structured pruning scenario for this demonstration with SIMD=1."
      ],
      "metadata": {
        "id": "RKatTp55emtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from model_compression_toolkit.target_platform_capabilities.target_platform import Signedness\n",
        "tp = mct.target_platform\n",
        "\n",
        "simd_size = 1\n",
        "\n",
        "def get_tpc():\n",
        "    # Define the default weight attribute configuration\n",
        "    default_weight_attr_config = tp.AttributeQuantizationConfig(\n",
        "        weights_quantization_method=tp.QuantizationMethod.UNIFORM,\n",
        "        weights_n_bits=None,\n",
        "        weights_per_channel_threshold=None,\n",
        "        enable_weights_quantization=None,\n",
        "        lut_values_bitwidth=None\n",
        "    )\n",
        "\n",
        "    # Define the OpQuantizationConfig\n",
        "    default_config = tp.OpQuantizationConfig(\n",
        "        default_weight_attr_config=default_weight_attr_config,\n",
        "        attr_weights_configs_mapping={},\n",
        "        activation_quantization_method=tp.QuantizationMethod.UNIFORM,\n",
        "        activation_n_bits=8,\n",
        "        supported_input_activation_n_bits=8,\n",
        "        enable_activation_quantization=None,\n",
        "        quantization_preserving=None,\n",
        "        fixed_scale=None,\n",
        "        fixed_zero_point=None,\n",
        "        simd_size=simd_size,\n",
        "        signedness=Signedness.AUTO\n",
        "    )\n",
        "\n",
        "    # Create the quantization configuration options and model\n",
        "    default_configuration_options = tp.QuantizationConfigOptions([default_config])\n",
        "    tp_model = tp.TargetPlatformModel(default_configuration_options)\n",
        "\n",
        "    # Return the target platform capabilities\n",
        "    tpc = tp.TargetPlatformCapabilities(tp_model)\n",
        "    return tpc\n"
      ],
      "metadata": {
        "id": "wqZ71s70jXhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Representative Dataset\n",
        "\n",
        "We are creating a representative dataset to guide our model pruning process for computing importance score for each channel:"
      ],
      "metadata": {
        "id": "SnKxedEgqdSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def representative_data_gen():\n",
        "  indices = random.sample(range(len(train_images)), 32)\n",
        "  yield [np.stack([train_images[i] for i in indices])]"
      ],
      "metadata": {
        "id": "SCiXV1s9jswp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Resource Utilization constraint\n",
        "\n",
        "We're defining a resource_utilization limit to constrain the memory usage of our pruned model.\n",
        "\n",
        "By setting a target that limits the model's weight memory to half of its original size (around 427KB), we aim to achieve a compression ratio of 50%:"
      ],
      "metadata": {
        "id": "nylQtALnr9gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a ResourceUtilization object to limit the pruned model weights memory to a certain resource constraint\n",
        "dense_model_memory = 427*(2**10) # Original model weights requiers ~427KB\n",
        "compression_ratio = 0.5\n",
        "\n",
        "resource_utilization = mct.core.ResourceUtilization(weights_memory=dense_model_memory*compression_ratio)"
      ],
      "metadata": {
        "id": "doJgwbSxsCbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prune Model\n",
        "\n",
        "We're ready to execute the actual pruning using MCT's keras_pruning_experimental function. The model is pruned according to our defined target Resource Utilization and using the representative dataset generated earlier.\n",
        "\n",
        "Each channel's importance is measured using LFH (Label-Free-Hessian)\n",
        "which approximates the Hessian of the loss function w.r.t model's weights.\n",
        "\n",
        "In this example, we've used just one score approximation for efficiency. Although this is less time-consuming, it's worth noting that using multiple approximations would yield more precise importance scores in real-world applications. However, this precision comes with a trade-off in terms of longer processing times.\n",
        "\n",
        "The result is a pruned model and associated pruning information, which includes details about the pruning masks and scores for each layer."
      ],
      "metadata": {
        "id": "xSP6815rsCnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_score_approximations = 1\n",
        "\n",
        "target_platform_cap = get_tpc()\n",
        "pruned_model, pruning_info = mct.pruning.keras_pruning_experimental(\n",
        "        model=model,\n",
        "        target_resource_utilization=resource_utilization,\n",
        "        representative_data_gen=representative_data_gen,\n",
        "        target_platform_capabilities=target_platform_cap,\n",
        "        pruning_config=mct.pruning.PruningConfig(num_score_approximations=num_score_approximations)\n",
        "    )"
      ],
      "metadata": {
        "id": "x4taG-5TxBrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pruned Model Properties\n",
        "\n",
        "As before, we can use Keras model's API to observe the new architecture and details of the pruned model:"
      ],
      "metadata": {
        "id": "iPd6ezZN2DNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model.summary()"
      ],
      "metadata": {
        "id": "xZu4gPwz2Ptp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retraining Pruned Model\n",
        "\n",
        "After pruning models, it's common to observe a temporary drop in the model's accuracy. This decline directly results from reducing the model's complexity through pruning."
      ],
      "metadata": {
        "id": "pAheQ9SGxB13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "pruned_model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "Vpihq5fpdeSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, to recover the performance, we retrain the pruned model, allowing it to adapt to its new, compressed architecture. The model can regain, and sometimes even surpass, its original accuracy through retraining."
      ],
      "metadata": {
        "id": "IHORL34t17bA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model.fit(train_images, train_labels, epochs=6, validation_data=(test_images, test_labels))\n",
        "pruned_model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "q00zV9Jmjszo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb7e1572"
      },
      "source": [
        "Copyright 2023 Sony Semiconductor Israel, Inc. All rights reserved.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n"
      ]
    }
  ]
}
